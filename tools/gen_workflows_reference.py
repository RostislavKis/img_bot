# -*- coding: utf-8 -*-
"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä WORKFLOWS_REFERENCE.md –∏–∑ JSON —Ñ–∞–π–ª–æ–≤.
–î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ (–±–µ–∑ timestamp) –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –∫–æ–º–º–∏—Ç–æ–≤.
"""

from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, List, Tuple

ROOT = Path(__file__).resolve().parents[1]
WF_DIR = ROOT / "workflows"
OUT = ROOT / "docs" / "WORKFLOWS_REFERENCE.md"

VIDEO_EXT = {".mp4", ".webm", ".mov", ".mkv", ".avi", ".gif"}
IMAGE_EXT = {".png", ".jpg", ".jpeg", ".webp", ".bmp"}


def _load_workflow_json(path: Path) -> Dict[str, Any]:
    return json.loads(path.read_text(encoding="utf-8"))


def _normalize_nodes(nodes: Any) -> Dict[str, Dict[str, Any]]:
    """
    ComfyUI workflow JSON –º–æ–∂–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å nodes –∫–∞–∫ dict (node_id->node)
    –∏–ª–∏ –∫–∞–∫ list (–≥–¥–µ node.get('id') —è–≤–ª—è–µ—Ç—Å—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º).
    –ü—Ä–∏–≤–æ–¥–∏–º –∫ dict[str, dict].
    """
    if isinstance(nodes, dict):
        out: Dict[str, Dict[str, Any]] = {}
        for k, v in nodes.items():
            if isinstance(v, dict):
                out[str(k)] = v
        return out

    if isinstance(nodes, list):
        out = {}
        for node in nodes:
            if not isinstance(node, dict):
                continue
            nid = node.get("id")
            if nid is None:
                continue
            out[str(nid)] = node
        return out

    return {}


def _guess_kind(nodes: Dict[str, Dict[str, Any]]) -> str:
    """–≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –ø–æ class_type –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É JSON."""
    if not nodes:
        return "unknown"

    # –ë—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å: –ø–æ class_type
    has_save_image = False
    has_video = False

    for node in nodes.values():
        ct = str(node.get("class_type", "")).lower()
        if ct in ("saveimage", "save_image"):
            has_save_image = True
        if "videocombine" in ct or ("video" in ct and ("combine" in ct or "save" in ct)):
            has_video = True
        if "vhs_videocombine" in ct:
            has_video = True

    if has_video:
        return "video"
    if has_save_image:
        return "image"

    # –ú–µ–¥–ª–µ–Ω–Ω—ã–π –ø—É—Ç—å: –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
    text = json.dumps(nodes, ensure_ascii=False).lower()
    if "vhs_videocombine" in text:
        return "video"
    if "saveimage" in text or '"images"' in text:
        return "image"
    return "unknown"


def _find_prompt_inputs(nodes: Dict[str, Dict[str, Any]]) -> List[str]:
    hits = set()
    for node in nodes.values():
        if not isinstance(node, dict):
            continue
        inputs = node.get("inputs", {})
        if not isinstance(inputs, dict):
            continue
        for k in inputs.keys():
            lk = str(k).lower()
            if lk in ("text", "prompt", "positive", "pos_prompt"):
                hits.add(str(k))
    return sorted(hits)


def _has_load_image(nodes: Dict[str, Dict[str, Any]]) -> bool:
    for node in nodes.values():
        ct = str(node.get("class_type", "")).lower()
        if ct in ("loadimage", "load_image"):
            return True
    return False


def _has_mask(nodes: Dict[str, Dict[str, Any]]) -> bool:
    # –ú–∞—Å–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≥–¥–µ —É–≥–æ–¥–Ω–æ, –∏—â–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É
    text = json.dumps(nodes, ensure_ascii=False).lower()
    return "mask" in text


def _collect_outputs(nodes: Dict[str, Dict[str, Any]]) -> List[str]:
    """
    –í workflow JSON outputs –æ–±—ã—á–Ω–æ –Ω–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã —è–≤–Ω–æ.
    –ò—â–µ–º –ø–æ –Ω–æ–¥–∞–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (SaveImage / VideoCombine –∏ —Ç.–ø.)
    """
    outs: List[str] = []
    for nid, node in nodes.items():
        ct = str(node.get("class_type", ""))
        lct = ct.lower()

        if lct in ("saveimage", "save_image"):
            outs.append(f"{nid}: {ct} -> images[]")
            continue

        if "videocombine" in lct or ("video" in lct and ("combine" in lct or "save" in lct)):
            outs.append(f"{nid}: {ct} -> video")
            continue

        if "save" in lct and ("gif" in lct or "anim" in lct):
            outs.append(f"{nid}: {ct} -> animation")
            continue

    return outs


def _md_escape_cell(text: str) -> str:
    # –ß—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É
    return (text or "").replace("|", "\\|").replace("\n", " ")


def main() -> int:
    if not WF_DIR.exists():
        raise SystemExit(f"Workflows dir not found: {WF_DIR}")

    files = sorted(WF_DIR.glob("*.json"), key=lambda p: p.name.lower())

    details: List[Tuple[str, str, bool, bool, List[str], List[str]]] = []

    for p in files:
        data = _load_workflow_json(p)
        nodes_raw = data.get("nodes") if isinstance(data, dict) else None
        nodes = _normalize_nodes(nodes_raw)
        kind = _guess_kind(nodes)
        has_load = _has_load_image(nodes)
        has_mask = _has_mask(nodes)
        prompts = _find_prompt_inputs(nodes)
        outs = _collect_outputs(nodes)

        details.append((p.stem, kind, has_load, has_mask, prompts, outs))

    # –î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–´–ô –í–´–í–û–î: –Ω–∏–∫–∞–∫–æ–π –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏/—Å–ª—É—á–∞–π–Ω–æ—Å—Ç–µ–π
    lines: List[str] = []
    lines.append("# üìö –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ø–æ Workflows (img_bot)")
    lines.append("")
    lines.append("–≠—Ç–æ—Ç —Ñ–∞–π–ª –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è —Å–∫—Ä–∏–ø—Ç–æ–º `tools/gen_workflows_reference.py` –Ω–∞ –æ—Å–Ω–æ–≤–µ JSON –∏–∑ –ø–∞–ø–∫–∏ `workflows/`.")
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("## üìã –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞")
    lines.append("")
    lines.append("| Workflow | –¢–∏–ø | LoadImage | Mask | Prompt-–ø–æ–ª—è | –í—ã—Ö–æ–¥—ã (–ø–æ –Ω–æ–¥–∞–º) |")
    lines.append("|---|---:|:---:|:---:|---|---|")

    for name, kind, has_load, has_mask, prompts, outs in details:
        lines.append(
            "| `{}` | {} | {} | {} | {} | {} |".format(
                name,
                _md_escape_cell(kind),
                "‚úÖ" if has_load else "‚Äî",
                "‚úÖ" if has_mask else "‚Äî",
                _md_escape_cell(", ".join(prompts) if prompts else "‚Äî"),
                _md_escape_cell("; ".join(outs) if outs else "‚Äî"),
            )
        )

    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("## üìÑ –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –ø–æ –∫–∞–∂–¥–æ–º—É workflow")
    lines.append("")

    for name, kind, has_load, has_mask, prompts, outs in details:
        lines.append(f"### `{name}.json`")
        lines.append("")
        lines.append(f"- **–¢–∏–ø:** `{kind}`")
        lines.append(f"- **LoadImage:** {'–¥–∞' if has_load else '–Ω–µ—Ç'}")
        lines.append(f"- **Mask:** {'–¥–∞' if has_mask else '–Ω–µ—Ç'}")
        lines.append(f"- **Prompt-–ø–æ–ª—è:** {', '.join(prompts) if prompts else '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏'}")
        lines.append("- **–í—ã—Ö–æ–¥—ã (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–æ–¥–∞–º):**")
        if outs:
            for o in outs:
                lines.append(f"  - {o}")
        else:
            lines.append("  - –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (–ø—Ä–æ–≤–µ—Ä—å –Ω–æ–¥—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)")
        lines.append("")
        lines.append("**–ó–∞–º–µ—Ç–∫–∏:** –¥–æ–ø–æ–ª–Ω–∏ –≤—Ä—É—á–Ω—É—é (VRAM, –≤—Ä–µ–º—è, —Ç–æ—á–Ω—ã–µ –≤—Ö–æ–¥—ã), –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        lines.append("")
        lines.append("---")
        lines.append("")

    OUT.parent.mkdir(parents=True, exist_ok=True)
    OUT.write_text("\n".join(lines), encoding="utf-8")

    print(f"OK: wrote {OUT} ({OUT.stat().st_size} bytes)")
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())

