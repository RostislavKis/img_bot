from __future__ import annotations

import asyncio
import json
import os
import random
import re
from io import BytesIO
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, NamedTuple

from aiogram import Router, F
from aiogram.filters import Command
from aiogram.types import CallbackQuery, Message, BufferedInputFile
from aiogram.fsm.context import FSMContext
from aiogram.exceptions import TelegramBadRequest

from bot.states import GenStates
from bot.keyboards.main_menu import get_back_keyboard, get_main_menu_keyboard
from comfy.client import ComfyUIClient
from comfy.workflow_loader import WorkflowLoader
from utils.logger import get_logger
from utils.files import ensure_comfy_input_image, save_telegram_photo, validate_input_image

router = Router()
log = get_logger(__name__)

_TRANSLATE_ENABLED = os.getenv("PROMPT_TRANSLATE", "1") != "0"
_CYR = re.compile(r"[–ê-–Ø–∞-—è–Å—ë]")
_translate_cache: dict[str, str] = {}
_translate_warned = False


# Workflow constants
WORKFLOW_IMAGE_DEFAULT = "image_default"
WORKFLOW_IMAGE_REFINER = "sdxl_base_refiner"
WORKFLOW_FLUX_DEV_IMG2IMG = "flux_dev_fp8_img2img"
WORKFLOW_FLUX_SCHNELL_IMG2IMG = "flux_schnell_fp8_img2img"


def _translate_ru_to_en_if_needed(text: str) -> str:
    global _translate_warned
    if not _TRANSLATE_ENABLED:
        return text
    if not text or not _CYR.search(text):
        return text
    if text in _translate_cache:
        return _translate_cache[text]
    try:
        from argostranslate import translate as _argos_translate
        out = _argos_translate.translate(text, "ru", "en")
        out = out.strip() if isinstance(out, str) else text
        _translate_cache[text] = out
        return out
    except Exception:
        if not _translate_warned:
            _translate_warned = True
            log.warning("PROMPT_TRANSLATE –≤–∫–ª—é—á–µ–Ω, –Ω–æ argostranslate –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω/–Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è—é RU –∫–∞–∫ –µ—Å—Ç—å")
        return text


# -----------------------------
# HunyuanVideo VRAM-aware presets + auto-fallback
# -----------------------------
HUNYUAN_PRESETS = [
    # 360p (fast mode)
    dict(name="360p", width=640, height=360, num_frames=25, fps=12, steps=12, cfg=5.5, batch_size=1, weight_dtype="fp8_e4m3fn_fast"),
    # 480p (quality mode default)
    dict(name="480p", width=854, height=480, num_frames=33, fps=12, steps=18, cfg=6.2, batch_size=1, weight_dtype="fp8_e4m3fn_fast"),
    # 720p (requires high VRAM)
    dict(name="720p", width=1280, height=720, num_frames=49, fps=16, steps=20, cfg=6.2, batch_size=1, weight_dtype="fp8_e4m3fn_fast"),
]

def _is_oom_error(err: str | None) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—à–∏–±–∫–∞ OOM."""
    if not err:
        return False
    e = err.lower()
    return ("out of memory" in e) or ("cuda oom" in e) or ("allocation on device" in e) or ("oom" in e)

def _pick_hunyuan_preset_index(system_stats: dict | None) -> int:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –ø—Ä–µ—Å–µ—Ç –ø–æ VRAM (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –≤ HUNYUAN_PRESETS.
    """
    try:
        sys_part = (system_stats or {}).get("system") or {}
        devs = (system_stats or {}).get("devices") or (system_stats or {}).get("device") or []

        cuda_dev = None
        if isinstance(devs, list):
            for d in devs:
                if str(d.get("type", "")).lower().startswith("cuda") or str(d.get("name", "")).lower().startswith("cuda"):
                    cuda_dev = d
                    break
            if cuda_dev is None and devs:
                cuda_dev = devs[0]
        elif isinstance(devs, dict):
            cuda_dev = devs

        vram_total = None
        vram_free = None
        for src in [cuda_dev or {}, sys_part]:
            for k in ["vram_total", "vram_total_mb", "gpu_vram_total", "total_vram", "total_vram_mb"]:
                if k in src:
                    vram_total = src.get(k)
                    break
            for k in ["vram_free", "vram_free_mb", "gpu_vram_free", "free_vram", "free_vram_mb"]:
                if k in src:
                    vram_free = src.get(k)
                    break

        def _to_mb(x):
            if x is None:
                return None
            if isinstance(x, (int, float)):
                # –∏–Ω–æ–≥–¥–∞ —ç—Ç–æ bytes
                if x > 1024 * 1024 * 1024:
                    return int(x / (1024 * 1024))
                return int(x)
            return None

        vram_total_mb = _to_mb(vram_total)
        vram_free_mb = _to_mb(vram_free)

        if not vram_total_mb and not vram_free_mb:
            return 0

        budget = vram_free_mb or vram_total_mb
        if budget is None:
            return 0

        # –ü–æ—Ä–æ–≥–∏ VRAM –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø—Ä–µ—Å–µ—Ç–∞
        if budget >= 11000:
            return 2  # 720p
        if budget >= 8500:
            return 1  # 480p
        return 0      # 360p
    except Exception:
        return 0

@router.message(Command("status"))
async def cmd_status(message: Message) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ ComfyUI –∏ –æ—á–µ—Ä–µ–¥–∏."""
    client = getattr(message.bot, "comfy_client", None)
    loader = getattr(message.bot, "workflow_loader", None)

    if client is None:
        await message.answer("‚ùå ComfyUI client –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ –±–æ—Ç–µ.")
        return

    try:
        stats = await client.system_stats()
    except Exception as e:
        await message.answer(f"‚ùå –ù–µ —Å–º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å /system_stats: {e}")
        return

    try:
        q = await client.get_queue_status()
    except Exception as e:
        q = {"error": str(e)}

    sys_part = (stats or {}).get("system") or {}
    comfy_ver = sys_part.get("comfyui_version", "?")
    py_ver = sys_part.get("python_version", "?")
    torch_ver = sys_part.get("pytorch_version", "?")

    q_running = len((q or {}).get("queue_running") or []) if isinstance(q, dict) else "?"
    q_pending = len((q or {}).get("queue_pending") or []) if isinstance(q, dict) else "?"

    wf_count = None
    if loader is not None:
        wf_count = len(loader.get_available_workflows()) if hasattr(loader, "get_available_workflows") else None

    text = (
        f"**ComfyUI:** {comfy_ver}\n"
        f"**Python:** {py_ver}\n"
        f"**PyTorch:** {torch_ver}\n"
        f"**Queue:** running={q_running}, pending={q_pending}\n"
    )
    if wf_count:
        text += f"**Workflows indexed:** {wf_count}\n"

    devs = (stats or {}).get("devices")
    if devs:
        try:
            if isinstance(devs, list) and devs:
                d0 = devs[0]
                name = d0.get("name") or d0.get("device") or "device0"
                vram_t = d0.get("vram_total") or d0.get("vram_total_mb")
                vram_f = d0.get("vram_free") or d0.get("vram_free_mb")
                if vram_t or vram_f:
                    text += f"**GPU:** {name} (vram_total={vram_t}, vram_free={vram_f})\n"
        except Exception:
            pass

    await message.answer(text, parse_mode="Markdown")


@router.message(Command("i2v"))
async def cmd_i2v(message: Message, state: FSMContext, t, lang) -> None:
    """–†–µ–∂–∏–º I2V: —Ñ–æ—Ç–æ + –ø—Ä–æ–º–ø—Ç –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ prefix video:."""
    await state.update_data(generation_mode="video", force_video=True, video_quality=False)
    await state.set_state(GenStates.waiting_prompt)
    msg = "üé¨ <b>I2V —Ä–µ–∂–∏–º</b>\n\n"
    msg += "–û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –∏ –ø—Ä–æ–º–ø—Ç –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º (–∏–ª–∏ —Å–Ω–∞—á–∞–ª–∞ —Ñ–æ—Ç–æ, –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç).\n"
    msg += "–ü—Ä–∏–º–µ—Ä: <code>–∫–æ—Ç –ø—Ä—ã–≥–∞–µ—Ç —á–µ—Ä–µ–∑ –∑–∞–±–æ—Ä</code>"
    await message.answer(msg, reply_markup=get_back_keyboard(lang), parse_mode="HTML")


@router.message(Command("videoq"))
async def cmd_videoq(message: Message, state: FSMContext, t, lang) -> None:
    """Quality mode –¥–ª—è HunyuanVideo (–ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç 480p)."""
    await state.update_data(generation_mode="video", force_video=True, video_quality=True)
    await state.set_state(GenStates.waiting_prompt)
    msg = "üé¨ <b>–í–∏–¥–µ–æ QUALITY</b>\n\n"
    msg += "–ù–∞–ø–∏—à–∏ –ø—Ä–æ–º–ø—Ç (–º–æ–∂–Ω–æ –±–µ–∑ prefix).\n"
    msg += "–ü—Ä–∏–º–µ—Ä: <code>–ø–∏—Ç–±—É–ª—å –±–µ–∂–∏—Ç –ø–æ –ø–ª—è–∂—É</code>"
    await message.answer(msg, reply_markup=get_back_keyboard(lang), parse_mode="HTML")


class PromptTarget(NamedTuple):
    """–¶–µ–ª–µ–≤–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –∏–Ω–∂–µ–∫—Ç–∞ –ø—Ä–æ–º–ø—Ç–∞."""
    node_id: str
    class_type: str
    key: str


PROMPT_KEYS = (
    "text",
    "prompt",
    "positive",
    "positive_prompt",
    "prompt_text",
    "text_g",
    "text_l",
    "clip_text",
    "conditioning_text",
)

NEG_KEYS_HINTS = ("negative", "neg", "bad", "undesired")


def _parse_prefix(text: str, default_mode: str = "dev") -> Tuple[str, str]:
    """
    –†–∞–∑–±–∏—Ä–∞–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å—ã –≤ —Ç–µ–∫—Å—Ç–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (workflow_name, clean_prompt).
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã:
    ‚Ä¢ dev: / fluxdev:        ‚Üí flux_dev_fp8 (–∫–∞—á–µ—Å—Ç–≤–æ FLUX)
    ‚Ä¢ schnell: / fast:       ‚Üí flux_schnell_fp8 (–±—ã—Å—Ç—Ä–æ FLUX)
    ‚Ä¢ xl: / photo:           ‚Üí sdxl_base_refiner (—Ñ–æ—Ç–æ-—Ä–µ–∞–ª–∏–∑–º SDXL)
    ‚Ä¢ video: / vid:          ‚Üí video_hunyuan15_720p_api (–≤–∏–¥–µ–æ)
    ‚Ä¢ edit:                  ‚Üí image_default (—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ)
    
    default_mode –º–æ–∂–µ—Ç –±—ã—Ç—å: "dev", "schnell", "xl", "video", "edit"
    –ï—Å–ª–∏ default_mode="schnell" –∏ –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ ‚Üí flux_schnell_fp8.
    """
    t = (text or "").strip()
    low = t.lower()

    def cut(pfx: str) -> str:
        return t[len(pfx):].strip()

    # Video (HunyuanVideo 1.5 - 720p API format)
    if low.startswith("video:"):
        return "video_hunyuan15_720p_api", cut("video:")
    if low.startswith("vid:"):
        return "video_hunyuan15_720p_api", cut("vid:")

    # Edit (—Ç–µ–ø–µ—Ä—å —á–µ—Ä–µ–∑ image_default)
    if low.startswith("edit:"):
        return "image_default", cut("edit:")

    # FLUX Schnell (–±—ã—Å—Ç—Ä–æ)
    if low.startswith("schnell:"):
        return "flux_schnell_fp8", cut("schnell:")
    if low.startswith("fast:"):
        return "flux_schnell_fp8", cut("fast:")

    # FLUX Dev (–∫–∞—á–µ—Å—Ç–≤–æ)
    if low.startswith("fluxdev:"):
        return "flux_dev_fp8", cut("fluxdev:")
    if low.startswith("dev:"):
        return "flux_dev_fp8", cut("dev:")

    # SDXL (—Ñ–æ—Ç–æ-—Ä–µ–∞–ª–∏–∑–º)
    if low.startswith("xl:"):
        return "sdxl_base_refiner", cut("xl:")
    if low.startswith("photo:"):
        return "sdxl_base_refiner", cut("photo:")

    # Default
    default_workflow = {
        "dev": "flux_dev_fp8",
        "schnell": "flux_schnell_fp8",
        "xl": "sdxl_base_refiner",
        "video": "video_hunyuan15_720p_api",
        "edit": "image_default",
    }.get(default_mode, "flux_dev_fp8")

    log.debug(f"Using default workflow: {default_workflow} (mode={default_mode})")
    return default_workflow, t


def _is_negative_field(key: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –∫–ª—é—á –∫ negative/conditioning."""
    k = (key or "").lower()
    return any(x in k for x in NEG_KEYS_HINTS)


def _find_prompt_targets(workflow: Dict[str, Any]) -> List[PromptTarget]:
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç workflow –∏ –Ω–∞—Ö–æ–¥–∏—Ç –í–°–ï —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è –∏–Ω–∂–µ–∫—Ç–∞ –ø—Ä–æ–º–ø—Ç–∞.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ PromptTarget (node_id, class_type, key).
    
    –õ–æ–≥–∏–∫–∞:
    1) –§–∞–∑–∞ 1: –∏—â–µ—Ç inputs —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ PROMPT_KEYS
    2) –§–∞–∑–∞ 2 (fallback): –ø–æ–ª—è —Å "prompt" –∏–ª–∏ "text" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
    3) –ò–°–ö–õ–Æ–ß–ê–ï–¢: –Ω–æ–¥—ã —Å "negative" –≤ key –ò CLIPTextEncode —Å –∏–Ω–¥–µ–∫—Å–æ–º >= 3
    """
    targets: List[PromptTarget] = []
    
    # –§–∞–∑–∞ 1: –∏—â–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ PROMPT_KEYS
    for node_id, node in workflow.items():
        if not isinstance(node, dict):
            continue
        
        class_type = str(node.get("class_type") or "unknown")
        inputs = node.get("inputs")
        if not isinstance(inputs, dict):
            continue
        
        for prompt_key in PROMPT_KEYS:
            if prompt_key in inputs and isinstance(inputs.get(prompt_key), str):
                if not _is_negative_field(prompt_key):
                    target = PromptTarget(node_id=str(node_id), class_type=class_type, key=prompt_key)
                    targets.append(target)
    
    # –§–∞–∑–∞ 2: fallback ‚Äî –∏—â–µ–º "prompt" –∏–ª–∏ "text" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏, –∏—Å–∫–ª—é—á–∞—è –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ
    if not targets:
        for node_id, node in workflow.items():
            if not isinstance(node, dict):
                continue
            
            class_type = str(node.get("class_type") or "unknown")
            inputs = node.get("inputs")
            if not isinstance(inputs, dict):
                continue
            
            # –í–ê–ñ–ù–û: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º CLIPTextEncode —Å –∏–Ω–¥–µ–∫—Å–æ–º >= 3 (–≤—Ç–æ—Ä–∞—è –∏ –≤—ã—à–µ = –Ω–µ–≥–∞—Ç–∏–≤)
            node_idx = int(node_id) if node_id.isdigit() else 0
            if class_type == "CLIPTextEncode" and node_idx >= 3:
                log.debug(f"Skipping node {node_id} (CLIPTextEncode negative)")
                continue

            for k, v in inputs.items():
                if not isinstance(v, str):
                    continue
                lk = str(k).lower()
                if _is_negative_field(lk):
                    continue
                if ("prompt" in lk) or ("text" in lk):
                    target = PromptTarget(node_id=str(node_id), class_type=class_type, key=str(k))
                    targets.append(target)
    
    return sorted(targets, key=lambda t: (t.node_id, t.key))


def _inject_prompt(workflow: Dict[str, Any], prompt: str, negative_prompt: str = "") -> None:
    """
    –í—Å—Ç–∞–≤–ª—è–µ—Ç prompt –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π negative_prompt –≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è workflow.
    
    –õ–æ–≥–∏—Ä—É–µ—Ç –ö–ê–ñ–î–û–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:
    ‚úì inject node=6 class=CLIPTextEncode key=text len=109
    
    –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (updated==0) ‚Äî –≤—ã–≤–æ–¥–∏—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫—É—é —Ç–∞–±–ª–∏—Ü—É.
    """
    prompt = (prompt or "").strip()
    if not prompt:
        raise ValueError("–ü—É—Å—Ç–æ–π prompt")

    targets = _find_prompt_targets(workflow)
    updated = 0
    negative_updated = 0
    
    # –í—Å—Ç–∞–≤–ª—è–µ–º –≤ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ü–µ–ª–∏
    for target in targets:
        node = workflow.get(target.node_id, {})
        inputs = node.get("inputs", {})
        
        if target.key in inputs:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ —ç—Ç–æ negative –ø–æ–ª–µ
            if _is_negative_field(target.key) and negative_prompt:
                inputs[target.key] = negative_prompt
                negative_updated += 1
                log.info(f"‚úì inject negative node={target.node_id} class={target.class_type} key={target.key} len={len(negative_prompt)}")
            elif not _is_negative_field(target.key):
                inputs[target.key] = prompt
                updated += 1
                log.info(f"‚úì inject node={target.node_id} class={target.class_type} key={target.key} len={len(prompt)}")
    
    if updated == 0:
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –≤—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É –Ω–æ–¥ –∏ –∏—Ö string-–∫–ª—é—á–µ–π
        log.warning("‚ö†Ô∏è –ò–Ω–∂–µ–∫—Ç –ø—Ä–æ–º–ø—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü–æ—Å—Ç—Ä–æ–µ–Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è —Ç–∞–±–ª–∏—Ü–∞:")
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö class_type –∏ –∫–ª—é—á–µ–π
        table_rows = []
        all_class_types = set()
        
        for node_id, node in sorted(workflow.items()):
            if not isinstance(node, dict):
                continue
            
            class_type = str(node.get("class_type") or "unknown")
            all_class_types.add(class_type)
            
            inputs = node.get("inputs", {})
            string_keys = []
            
            for k, v in inputs.items():
                if isinstance(v, str):
                    string_keys.append(str(k))
            
            table_rows.append({
                "node_id": str(node_id),
                "class_type": class_type,
                "string_keys": ", ".join(string_keys) if string_keys else "(–Ω–µ—Ç)",
            })
        
        # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É
        log.warning("=" * 90)
        log.warning(f"{'Node ID':<10} {'Class Type':<25} {'String Keys in inputs':<50}")
        log.warning("-" * 90)
        for row in table_rows:
            log.warning(f"{row['node_id']:<10} {row['class_type']:<25} {row['string_keys']:<50}")
        log.warning("=" * 90)
        
        # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö class_type –≤ workflow
        log.warning(f"–í—Å–µ class_type –≤ workflow: {', '.join(sorted(all_class_types))}")
        log.warning(f"–ò–∑–≤–µ—Å—Ç–Ω—ã–µ PROMPT_KEYS: {', '.join(PROMPT_KEYS)}")
        
        raise ValueError(
            f"–í workflow –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.\n"
            f"–°–º–æ—Ç—Ä–∏ –ª–æ–≥–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–π —Ç–∞–±–ª–∏—Ü—ã –Ω–æ–¥."
        )


def _inject_negative_prompt(workflow: Dict[str, Any], negative_prompt: str) -> None:
    """–í—Å—Ç–∞–≤–ª—è–µ—Ç negative prompt –≤ –ø–æ–ª—è, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ negative/neg/bad/undesired."""
    negative_prompt = (negative_prompt or "").strip()
    if not negative_prompt:
        return

    updated = 0
    for node_id, node in workflow.items():
        if not isinstance(node, dict):
            continue
        inputs = node.get("inputs")
        if not isinstance(inputs, dict):
            continue
        for k, v in inputs.items():
            if not isinstance(v, str):
                continue
            if _is_negative_field(str(k)):
                inputs[k] = negative_prompt
                updated += 1

    if updated:
        log.info(f"‚úì inject negative prompt into {updated} fields")


def _inject_seed_steps_cfg(workflow: Dict[str, Any], *, steps: Optional[int] = None, cfg: Optional[float] = None) -> None:
    """–ú—è–≥–∫–æ –≤—Å—Ç–∞–≤–ª—è–µ—Ç seed/steps/cfg, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–ª—é—á–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç."""
    seed = random.randint(1, 2_000_000_000)
    for node_id, node in workflow.items():
        if not isinstance(node, dict):
            continue
        inputs = node.get("inputs")
        if not isinstance(inputs, dict):
            continue

        if "seed" in inputs:
            try:
                inputs["seed"] = int(seed)
            except Exception:
                pass

        if steps is not None and "steps" in inputs:
            try:
                inputs["steps"] = int(steps)
            except Exception:
                pass

        if cfg is not None:
            for k in ("cfg", "guidance", "guidance_scale"):
                if k in inputs:
                    try:
                        inputs[k] = float(cfg)
                    except Exception:
                        pass


def _inject_resolution(workflow: Dict[str, Any], *, width: Optional[int] = None, height: Optional[int] = None) -> None:
    """–ú—è–≥–∫–æ –≤—Å—Ç–∞–≤–ª—è–µ—Ç width/height, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–ª—é—á–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç."""
    if width is None and height is None:
        return
    updated = 0
    for node_id, node in workflow.items():
        if not isinstance(node, dict):
            continue
        inputs = node.get("inputs")
        if not isinstance(inputs, dict):
            continue
        if width is not None and "width" in inputs:
            try:
                inputs["width"] = int(width)
                updated += 1
            except Exception:

                pass
        if height is not None and "height" in inputs:
            try:
                inputs["height"] = int(height)
                updated += 1
            except Exception:
                pass
    if updated == 0:
        log.warning("No width/height fields found in workflow; consider adding ImageScale node.")


def _find_inputs(workflow: Dict[str, Any], key: str) -> List[Dict[str, Any]]:
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ inputs-dict, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∫–ª—é—á."""
    out: List[Dict[str, Any]] = []
    for node_id, node in workflow.items():
        if not isinstance(node, dict):
            continue
        inputs = node.get("inputs")
        if isinstance(inputs, dict) and key in inputs:
            out.append(inputs)
    return out


def _get_current_value(workflow: Dict[str, Any], key: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª—é—á–∞ –∏–∑ –≤—Å–µ—Ö –Ω–æ–¥."""
    for node_id, node in workflow.items():
        if not isinstance(node, dict):
            continue
        inputs = node.get("inputs")
        if isinstance(inputs, dict) and key in inputs:
            return str(inputs.get(key) or "").strip()
    return ""


def _choose_by_hint(available: List[str], hint: str) -> Optional[str]:
    """–í—ã–±–∏—Ä–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ (case-insensitive)."""
    h = (hint or "").lower()
    for n in available:
        if h in n.lower():
            return n
    return None


def _choose_checkpoint(available: List[str], workflow_name: str, current: str) -> str:
    """
    –í—ã–±–∏—Ä–∞–µ—Ç checkpoint –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é workflow.
    
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
    1) –ï—Å–ª–∏ workflow —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç valid checkpoint ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
    2) HunyuanVideo ‚Üí –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç checkpoint, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    3) video_sd15 ‚Üí –¢–û–õ–¨–ö–û SD1.5 (–∑–∞–ø—Ä–µ—Ç–∏—Ç—å SDXL)
    4) FLUX workflows ‚Üí –∏—â–µ–º flux1-dev –∏–ª–∏ flux1-schnell
    5) SDXL ‚Üí –∏—â–µ–º RealVisXL –∏–ª–∏ Jugger–Ω–∞—É—ÇXL
    6) Fallback ‚Üí –ø–µ—Ä–≤—ã–π –≤ —Å–ø–∏—Å–∫–µ
    """
    if not available:
        raise RuntimeError("–í ComfyUI –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ checkpoint (models\\checkpoints –ø—É—Å—Ç).")

    if current and current in available:
        log.debug(f"Checkpoint —É–∂–µ –∑–∞–¥–∞–Ω –≤ workflow: {current}")
        return current

    w = (workflow_name or "").lower()

    # HunyuanVideo (–ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç checkpoint)
    if "hunyuan" in w:
        log.info(f"HunyuanVideo workflow –ù–ï —Ç—Ä–µ–±—É–µ—Ç checkpoint –≤—ã–±–æ—Ä–∞")
        return ""

    # VIDEO SD1.5 (–∂—ë—Å—Ç–∫–∏–π –≤—ã–±–æ—Ä —Ç–æ–ª—å–∫–æ SD1.5, –ù–ï SDXL)
    if "video_sd15" in w or workflow_name == "video_sd15":
        sd15_candidates = [
            c for c in available
            if (("sd15" in c.lower()) or ("sd_15" in c.lower()) or ("1.5" in c.lower()) or ("v1-5" in c.lower()))
            and ("xl" not in c.lower()) and ("sdxl" not in c.lower())
        ]
        if sd15_candidates:
            pick = sd15_candidates[0]
            log.info(f"video_sd15: Selected SD1.5 checkpoint: {pick}")
            return pick
        else:
            available_list = ", ".join(available)
            raise RuntimeError(
                f"video_sd15 —Ç—Ä–µ–±—É–µ—Ç SD1.5 checkpoint, –Ω–æ –Ω–∞–π–¥–µ–Ω—ã —Ç–æ–ª—å–∫–æ: {available_list}.\n"
                f"–ü–µ—Ä–µ–∏–º–µ–Ω—É–π/–¥–æ–±–∞–≤—å SD1.5 checkpoint —Å 'sd15', '1.5' –∏–ª–∏ 'v1-5' –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏."
            )

    # FLUX Dev (–∫–∞—á–µ—Å—Ç–≤–æ)
    if "flux_dev" in w or (w == "flux_dev_fp8"):
        pick = _choose_by_hint(available, "flux1-dev") or _choose_by_hint(available, "dev-fp8")
        if pick:
            log.debug(f"FLUX Dev selected: {pick}")
            return pick

    # FLUX Schnell (–±—ã—Å—Ç—Ä–æ)
    if "flux_schnell" in w or (w == "flux_schnell_fp8"):
        pick = _choose_by_hint(available, "flux1-schnell") or _choose_by_hint(available, "schnell-fp8")
        if pick:
            log.debug(f"FLUX Schnell selected: {pick}")
            return pick

    # SDXL (—Ñ–æ—Ç–æ-—Ä–µ–∞–ª–∏–∑–º)
    if "sdxl" in w or "photo" in w or "xl" in w:
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: RealVisXL ‚Üí Jugger–Ω–∞—É—ÇXL ‚Üí SD_XL_base ‚Üí –ø–µ—Ä–≤—ã–π
        pick = (
            _choose_by_hint(available, "RealVisXL")
            or _choose_by_hint(available, "JuggernautXL")
            or _choose_by_hint(available, "sd_xl_base")
            or available[0]
        )
        log.debug(f"SDXL selected: {pick}")
        return pick

    # Fallback: –ø–µ—Ä–≤—ã–π –≤ —Å–ø–∏—Å–∫–µ
    log.warning(f"No specific checkpoint hint matched for {workflow_name}, using first available: {available[0]}")
    return available[0]


def _choose_unet(available: List[str], workflow_name: str, current: str) -> str:
    """–í—ã–±–∏—Ä–∞–µ—Ç UNET –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é workflow."""
    if not available:
        raise RuntimeError("–í ComfyUI –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ UNET (UNETLoader –ø—É—Å—Ç).")

    if current and current in available:
        return current

    w = (workflow_name or "").lower()
    if "kontext" in w:
        return _choose_by_hint(available, "kontext") or available[0]
    if "fill" in w:
        return _choose_by_hint(available, "fill") or available[0]
    if "dev" in w or "flux_dev" in w:
        return _choose_by_hint(available, "dev") or available[0]
    return _choose_by_hint(available, "schnell") or available[0]


def _inject_image_filename(workflow: Dict[str, Any], comfy_input_name: str) -> bool:
    """–ü–æ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏–º—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ LoadImage nodes."""
    injected = False
    for node_id, node in workflow.items():
        if not isinstance(node, dict):
            continue
        class_type = str(node.get("class_type") or "")
        inputs = node.get("inputs")
        if not isinstance(inputs, dict):
            continue
        if "image" in inputs and isinstance(inputs.get("image"), str):
            if "LoadImage" in class_type or class_type.lower() == "loadimage":
                inputs["image"] = comfy_input_name
                injected = True

    if not injected:
        targets = _find_inputs(workflow, "image")
        for inp in targets:
            if isinstance(inp.get("image"), str):
                inp["image"] = comfy_input_name
                injected = True
                break

    return injected


def _inject_input_image(workflow: Dict[str, Any], file_name: str) -> None:
    """–ü—ã—Ç–∞–µ—Ç—Å—è –Ω–∞–π—Ç–∏ LoadImage node –∏ –∑–∞–º–µ–Ω–∏—Ç—å inputs.image."""
    for node_id, node in workflow.items():
        try:
            cls = str(node.get("class_type") or "")
            if cls == "LoadImage":
                node["inputs"]["image"] = file_name
                log.info(f"‚úì inject input image: node={node_id} file={file_name}")
                return
        except Exception:
            pass


def _inject_mask_image(workflow: Dict[str, Any], mask_file: str) -> bool:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –≤—Å—Ç–∞–≤–∏—Ç—å –º–∞—Å–∫—É –≤ workflow.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ö–æ—Ç—å –æ–¥–∏–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π input.
    """
    injected = False
    for node_id, node in workflow.items():
        try:
            inputs = node.get("inputs", {})
            if not isinstance(inputs, dict):
                continue
            for k in ("mask", "image_mask", "mask_image", "inpaint_mask"):
                if k in inputs and isinstance(inputs[k], str):
                    inputs[k] = mask_file
                    injected = True
                    log.info(f"‚úì inject mask image: node={node_id} key={k} file={mask_file}")
        except Exception:
            pass
    return injected


def _inject_denoise(workflow: Dict[str, Any], *, denoise: float | None) -> None:
    if denoise is None:
        return
    for _, node in workflow.items():
        if not isinstance(node, dict):
            continue
        inputs = node.get("inputs")
        if not isinstance(inputs, dict):
            continue
        if "denoise" in inputs:
            try:
                inputs["denoise"] = float(denoise)
            except Exception:
                pass


async def _send_result_to_telegram(message: Message, *, out_bytes: bytes, filename: str, mime: str) -> None:
    """
    –ù–∞–¥—ë–∂–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:
    - –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–≤
    - fallback: video -> document
    - fallback: photo -> document
    """
    from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
    
    caption = "‚úÖ –ì–æ—Ç–æ–≤–æ!"
    is_video = mime.startswith("video/") or filename.lower().endswith((".mp4", ".webm", ".mov", ".mkv"))
    is_gif = mime.startswith("image/gif") or filename.lower().endswith(".gif")
    is_image = mime.startswith("image/") and not is_gif

    async def _try_send(kind: str) -> None:
        if kind == "video":
            await message.answer_video(
                BufferedInputFile(out_bytes, filename=filename),
                caption=caption,
                supports_streaming=True,
            )
            return
        if kind == "photo":
            await message.answer_photo(
                BufferedInputFile(out_bytes, filename=filename),
                caption=caption,
            )
            return
        await message.answer_document(
            BufferedInputFile(out_bytes, filename=filename),
            caption=caption,
        )

    if is_video:
        order = ["video", "document"]
    elif is_image:
        order = ["photo", "document"]
    else:
        order = ["document"]

    last_err: Exception | None = None
    for kind in order:
        for attempt in range(1, 4):
            try:
                await _try_send(kind)
                return
            except Exception as e:
                last_err = e
                log.warning("Telegram send failed kind=%s attempt=%s: %s", kind, attempt, e)
                await asyncio.sleep(0.7 * attempt)
                continue
    if last_err:
        raise last_err


PHOTO_ACTION_ENHANCE = "photo:enhance"
PHOTO_ACTION_EDIT_PROMPT = "photo:edit_prompt"
PHOTO_ACTION_EDIT_MASK = "photo:edit_mask"


def _photo_actions_kb(lang: str):
    from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="‚ú® –£–ª—É—á—à–∏—Ç—å", callback_data=PHOTO_ACTION_ENHANCE)],
        [InlineKeyboardButton(text="‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å (–ø—Ä–æ–º–ø—Ç)", callback_data=PHOTO_ACTION_EDIT_PROMPT)],
        [InlineKeyboardButton(text="üé≠ –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å (–º–∞—Å–∫–∞ + –ø—Ä–æ–º–ø—Ç)", callback_data=PHOTO_ACTION_EDIT_MASK)],
    ])


async def _run_image_job(
    *,
    message: Message,
    client: ComfyUIClient,
    loader: WorkflowLoader,
    workflow_name: str,
    input_image_name: str,
    prompt: str,
    negative: str = "",
    mask_image_name: str | None = None,
    denoise: float | None = None,
    settings = None,
) -> None:
    wf_name = workflow_name
    if wf_name == WORKFLOW_IMAGE_REFINER and not _workflow_exists(loader, wf_name):
        wf_name = WORKFLOW_IMAGE_DEFAULT

    wf = loader.load(wf_name)
    _inject_input_image(wf, input_image_name)
    if mask_image_name:
        ok = _inject_mask_image(wf, mask_image_name)
        if not ok:
            log.warning("Mask mode requested but no mask inputs found in workflow=%s (mask will be ignored).", wf_name)
    _inject_denoise(wf, denoise=denoise)
    _inject_prompt(wf, prompt, negative_prompt=negative)

    pid = await client.queue_prompt(wf)
    if not pid:
        err = (client.last_error or "ComfyUI –æ—Ç–∫–ª–æ–Ω–∏–ª workflow").strip()[:800]
        raise RuntimeError(err)
    log.info("Prompt queued: %s (workflow=%s)", pid, wf_name)

    timeout_val = int(getattr(settings or {}, "comfy_timeout", 300)) if settings else 300
    result = await client.wait_for_result(pid, timeout=timeout_val)
    if not result:
        raise RuntimeError(client.last_error or "Timeout: ComfyUI –Ω–µ –≤–µ—Ä–Ω—É–ª output")

    filename = str(result["filename"])
    out_bytes = bytes(result["bytes"])
    mime = str(result.get("mime") or "application/octet-stream")

    log.info("Image result: filename=%s size=%s mime=%s node=%s", filename, len(out_bytes), mime, result.get("node_id"))
    await _send_result_to_telegram(message, out_bytes=out_bytes, filename=filename, mime=mime)


# =========================================================================
# CALLBACK HANDLERS
# ============================================================================
@router.callback_query(F.data == "action_generate_dev")
async def cb_generate_dev(call: CallbackQuery, state: FSMContext, t, lang):
    """–ö–ê–†–¢–ò–ù–ö–ê (DEV) ‚Äî –∫–∞—á–µ—Å—Ç–≤–æ"""
    await call.answer()
    await state.update_data(generation_mode="dev")
    await state.set_state(GenStates.waiting_prompt)
    msg = "üì∏ <b>–†–µ–∂–∏–º: –ö–∞—Ä—Ç–∏–Ω–∫–∞ (DEV)</b>\n\n"
    msg += "–í–≤–µ–¥–∏ –ø—Ä–æ–º–ø—Ç –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.\n"
    msg += "–õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, ~2 –º–∏–Ω—É—Ç—ã.\n\n"
    msg += "–ü—Ä–∏–º–µ—Ä:\n"
    msg += '<code>–∫—Ä–∞—Å–∏–≤–∞—è –¥–µ–≤—É—à–∫–∞ –≤ –∞–Ω–∏–º–µ-—Å—Ç–∏–ª–µ —Å –≥–æ–ª—É–±—ã–º–∏ –≥–ª–∞–∑–∞–º–∏</code>'
    await call.message.answer(msg, reply_markup=get_back_keyboard(lang), parse_mode="HTML")


@router.callback_query(F.data == "action_generate_schnell")
async def cb_generate_schnell(call: CallbackQuery, state: FSMContext, t, lang):
    """–ë–´–°–¢–†–û ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å"""
    await call.answer()
    await state.update_data(generation_mode="schnell")
    await state.set_state(GenStates.waiting_prompt)
    msg = "‚ö° <b>–†–µ–∂–∏–º: –ë—ã—Å—Ç—Ä–æ (Schnell)</b>\n\n"
    msg += "–í–≤–µ–¥–∏ –ø—Ä–æ–º–ø—Ç –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.\n"
    msg += "–•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, ~30 —Å–µ–∫—É–Ω–¥.\n\n"
    msg += "–ü—Ä–∏–º–µ—Ä:\n"
    msg += '<code>–∫–æ—Ç —Å–ø–∏—Ç –Ω–∞ –ø–æ–¥—É—à–∫–µ</code>'
    await call.message.answer(msg, reply_markup=get_back_keyboard(lang), parse_mode="HTML")


@router.callback_query(F.data == "action_generate_video")
async def cb_generate_video(call: CallbackQuery, state: FSMContext, t, lang):
    """–í–ò–î–ï–û ‚Äî AnimateDiff"""
    await call.answer()
    await state.update_data(generation_mode="video")
    await state.set_state(GenStates.waiting_prompt)
    msg = "üé¨ <b>–†–µ–∂–∏–º: –í–∏–¥–µ–æ</b>\n\n"
    msg += "–í–≤–µ–¥–∏ –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏.\n"
    msg += "16 —Ñ—Ä–µ–π–º–æ–≤ GIF, ~1-2 –º–∏–Ω—É—Ç—ã.\n\n"
    msg += "–ü—Ä–∏–º–µ—Ä:\n"
    msg += '<code>–∫–æ—Ç –ø—Ä—ã–≥–∞–µ—Ç —á–µ—Ä–µ–∑ –∑–∞–±–æ—Ä, —Å–æ–ª–Ω–µ—á–Ω—ã–π –¥–µ–Ω—å</code>'
    await call.message.answer(msg, reply_markup=get_back_keyboard(lang), parse_mode="HTML")


@router.callback_query(F.data == "action_generate_edit")
async def cb_generate_edit(call: CallbackQuery, state: FSMContext, t, lang):
    """–†–ï–î–ê–ö–¢–ò–†–û–í–ê–ù–ò–ï ‚Äî inpainting/image edit"""
    await call.answer()
    await state.update_data(generation_mode="edit")
    msg = "‚úèÔ∏è <b>–†–µ–∂–∏–º: –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ</b>\n\n"
    msg += "1) –û—Ç–ø—Ä–∞–≤—å —Å–≤–æ—ë —Ñ–æ—Ç–æ\n"
    msg += "2) –ù–∞–ø–∏—à–∏, —á—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å\n\n"
    msg += "–ü—Ä–∏–º–µ—Ä—ã:\n"
    msg += '<code>–ò–∑–º–µ–Ω–∏ —Ñ–æ–Ω –Ω–∞ –ø–ª—è–∂</code>\n'
    msg += '<code>–î–æ–±–∞–≤—å —Å–æ–ª–Ω–µ—á–Ω—ã–µ –æ—á–∫–∏</code>'
    await call.message.answer(msg, reply_markup=get_back_keyboard(lang), parse_mode="HTML")


# ============================================================================
# MESSAGE HANDLERS
# ============================================================================

@router.message(F.photo)
async def msg_photo(message: Message, state: FSMContext, settings, t, lang):
    """–ü–æ–ª—É—á–∞–µ–º —Ñ–æ—Ç–æ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."""
    try:
        ph = message.photo[-1]
        tg_file = await message.bot.get_file(ph.file_id)
        buf = BytesIO()
        await message.bot.download_file(tg_file.file_path, destination=buf)
        photo_bytes = buf.getvalue()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
        tmp_file = save_telegram_photo(photo_bytes, settings.tmp_dir, prefix="tg_photo")
        
        # –ö–æ–ø–∏—Ä—É–µ–º –≤ ComfyUI input (—Å—Ä–∞–∑—É, —á—Ç–æ–±—ã –±—ã–ª–æ –≥–æ—Ç–æ–≤–æ)
        comfy_filename = ensure_comfy_input_image(tmp_file, settings.comfy_input_dir)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ state
        await state.update_data(
            input_image_local_path=str(tmp_file),
            input_image_comfy_name=comfy_filename,
            last_photo_comfy=comfy_filename,
            pending_photo_action=None,
            mask_photo_comfy=None,
        )
        await state.set_state(GenStates.waiting_prompt)

        # –ü–æ–∫–∞–∑–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏—è —Å –∫–Ω–æ–ø–∫–∞–º–∏
        await message.answer(
            "üñº –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ. –ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å?",
            reply_markup=_photo_actions_kb(lang),
        )
    except Exception as e:
        log.exception(f"Photo receive failed: {e}")
        await message.answer(
            "‚ùå –ù–µ —Å–º–æ–≥—É –ø—Ä–∏–Ω—è—Ç—å —Ñ–æ—Ç–æ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.",
            reply_markup=get_main_menu_keyboard(lang),
        )


@router.message(GenStates.waiting_prompt, F.text)
async def msg_prompt(message: Message, state: FSMContext, settings, t, lang):
    """–û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: –ø—Ä–æ–º–ø—Ç ‚Üí workflow ‚Üí ComfyUI ‚Üí —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    raw = (message.text or "").strip()
    if not raw:
        await message.answer("‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º—Ç –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.", reply_markup=get_back_keyboard(lang))
        return

    if raw.startswith("/"):
        await state.clear()
        await message.answer("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=get_main_menu_keyboard(lang))
        return

    st = await state.get_data()
    
    # --- photo edit flow (FSMContext keys) ---
    pending = st.get("pending_photo_action")
    if pending in ("edit_prompt", "edit_mask_prompt"):
        last_photo = st.get("last_photo_comfy")
        mask_photo = st.get("mask_photo_comfy") if pending == "edit_mask_prompt" else None
        if not last_photo:
            await state.update_data(pending_photo_action=None, mask_photo_comfy=None)
            await message.answer("–ù–µ—Ç —Ñ–æ—Ç–æ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –∑–∞–Ω–æ–≤–æ.")
            return

        client = ComfyUIClient(settings.comfy_url, settings.comfy_timeout)
        loader = WorkflowLoader(settings.workflows_dir)

        wf_name = st.get("pending_photo_workflow") or WORKFLOW_IMAGE_DEFAULT
        denoise = st.get("pending_photo_denoise")
        if pending == "edit_mask_prompt":
            wf_name = WORKFLOW_IMAGE_DEFAULT
            if denoise is None:
                denoise = 0.65

        user_prompt = raw
        prompt = f"{user_prompt}. Keep the same subject identity and scene layout, realistic, natural light, coherent details."
        prompt = _translate_ru_to_en_if_needed(prompt)
        negative = "blurry, lowres, deformed, artifacts, bad anatomy, cartoon, anime, text, watermark"

        await message.answer("üõ†Ô∏è –†–µ–¥–∞–∫—Ç–∏—Ä—É—é‚Ä¶")
        try:
            await _run_image_job(
                message=message,
                client=client,
                loader=loader,
                workflow_name=wf_name,
                input_image_name=last_photo,
                mask_image_name=mask_photo,
                prompt=prompt,
                negative=negative,
                denoise=denoise,
                settings=settings,
            )
        except Exception as e:
            log.exception(f"Photo edit failed: {e}")
            await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        finally:
            await client.close()

        await state.update_data(pending_photo_action=None, mask_photo_comfy=None, pending_photo_workflow=None, pending_photo_denoise=None)
        await message.answer("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=get_main_menu_keyboard(lang))
        return

    st = await state.get_data()
    generation_mode = st.get("generation_mode", "dev")
    force_video = bool(st.get("force_video"))
    state_quality = bool(st.get("video_quality"))

    # –†–∞–∑–±–æ—Ä –ø—Ä–µ—Ñ–∏–∫—Å–∞ —Å —É—á—ë—Ç–æ–º —Ä–µ–∂–∏–º–∞ + quality mode
    low_raw = raw.lower().strip()
    quality_mode = state_quality
    if low_raw.startswith("videoq:"):
        quality_mode = True
        raw = "video:" + raw[len("videoq:"):]
    elif low_raw.startswith("videoq "):
        quality_mode = True
        raw = "video:" + raw[len("videoq "):]

    workflow_name, prompt = _parse_prefix(raw, default_mode=generation_mode)
    if force_video and not low_raw.startswith(("video:", "vid:", "videoq:", "videoq ")):
        workflow_name = "video_hunyuan15_720p_api"

    if not prompt:
        await message.answer("‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º—Ç –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.", reply_markup=get_back_keyboard(lang))
        return

    prompt = _translate_ru_to_en_if_needed(prompt)

    # –õ–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞ workflow –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Ñ–æ—Ç–æ (–≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
    input_image_comfy_name = st.get("input_image_comfy_name")
    if input_image_comfy_name:
        # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–æ—Ç–æ –∏ —é–∑–µ—Ä –Ω–µ —É–∫–∞–∑–∞–ª –ø—Ä–µ—Ñ–∏–∫—Å–∞:
        if workflow_name == "flux_dev_fp8" and generation_mode == "dev":
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ SDXL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ (—Ä–µ–∂–∏–º "–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
            workflow_name = "sdxl_base_refiner"
            log.info(f"–§–æ—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ workflow={workflow_name}")
        elif workflow_name == "flux_schnell_fp8" and generation_mode == "schnell":
            # Schnell –¥–ª—è —Ñ–æ—Ç–æ? –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ SDXL
            workflow_name = "sdxl_base_refiner"
            log.info(f"–§–æ—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ (fast mode): –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ workflow={workflow_name}")
        elif workflow_name == "video_default":
            # –í–∏–¥–µ–æ —Å —Ñ–æ—Ç–æ? –û–∫, –º–æ–∂–µ—Ç –±—ã—Ç—å animation –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            log.info(f"–§–æ—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ + video mode: –∏—Å–ø–æ–ª—å–∑—É–µ–º video_default —Å –≤—Ö–æ–¥–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º")
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω xl: –∏–ª–∏ sdxl ‚Äî –Ω–µ –º–µ–Ω—è–µ–º
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω edit: ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º image_default –∏–ª–∏ FLUX img2img (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)

    await state.set_state(GenStates.running)
    status_msg = await message.answer("‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞...", parse_mode="HTML")

    client: Optional[ComfyUIClient] = None
    try:
        loader = WorkflowLoader(settings.workflows_dir)
        wf = loader.load(workflow_name)

        log.info(f"Workflow loaded: {workflow_name}, nodes count: {len(wf)}")

        # –¢—é–Ω–∏–Ω–≥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if workflow_name == "video_hunyuan15_720p_api":
            # HunyuanVideo 1.5 I2V with VRAM-aware presets + auto-fallback
            log.info("HunyuanVideo 1.5 I2V API workflow detected - applying VRAM-aware presets")
            
            # 0) –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: –∏–∑ state –∏–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
            input_image_comfy_name = st.get("input_image_comfy_name")
            
            # –ü–æ–ª—É—á–∞–µ–º system_stats –¥–ª—è –≤—ã–±–æ—Ä–∞ —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ –ø—Ä–µ—Å–µ—Ç–∞
            if client is None:
                client = ComfyUIClient(settings.comfy_url, settings.comfy_timeout)
            system_stats = None
            try:
                system_stats = await client.system_stats()
            except Exception as e:
                log.warning(f"Failed to get system_stats: {e}")
            
            # –í—ã–±–∏—Ä–∞–µ–ºPreset
            start_idx = _pick_hunyuan_preset_index(system_stats)
            if quality_mode and start_idx < 1:
                start_idx = 1
            preset = HUNYUAN_PRESETS[start_idx]
            log.info(f"Selected Hunyuan preset: {preset['name']} ({preset['width']}x{preset['height']})")
            
            if not input_image_comfy_name:
                # –ù–µ—Ç —Ñ–æ—Ç–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ –∫–∞–¥—Ä–∞
                await status_msg.edit_text(
                    f"‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –∫–∞–¥—Ä {preset['width']}x{preset['height']}...", 
                    parse_mode="HTML"
                )
                
                try:
                    input_image_comfy_name = await _generate_start_image(
                        client=client,
                        loader=loader,
                        prompt=prompt,
                        settings=settings,
                        tmp_dir=Path(settings.tmp_dir),
                        comfy_input_dir=Path(settings.comfy_input_dir),
                        target_width=preset["width"],
                        target_height=preset["height"],
                    )
                    await status_msg.edit_text("‚úì –°—Ç–∞—Ä—Ç–æ–≤—ã–π –∫–∞–¥—Ä –≥–æ—Ç–æ–≤ ‚Äî –∑–∞–ø—É—Å–∫–∞—é –≤–∏–¥–µ–æ...", parse_mode="HTML")
                except Exception as e:
                    log.exception(f"Start image generation failed: {e}")
                    raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –∫–∞–¥—Ä –¥–ª—è I2V:\n{e}")
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Ñ–æ—Ç–æ
                if not validate_input_image(input_image_comfy_name, settings.comfy_input_dir):
                    raise RuntimeError(
                        f"–í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ '{input_image_comfy_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ.\n"
                        f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞–ø–∫—É {settings.comfy_input_dir}"
                    )
                log.info(f"Using user-provided image: {input_image_comfy_name}")
            
            # –í–∞–∂–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ filename –ø—É—Å—Ç–æ–π - fail
            if not input_image_comfy_name or not input_image_comfy_name.strip():
                raise RuntimeError(
                    "–ù—É–∂–Ω–∞ —Å—Ç–∞—Ä—Ç–æ–≤–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞ –¥–ª—è I2V.\n"
                    "–ü—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ –∏–ª–∏ –¥–æ–∂–¥–∏—Å—å –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞–¥—Ä–∞."
                )
            
            # –ò–Ω–∂–µ–∫—Ç–∏–º –≤—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ workflow
            _inject_hunyuan_input_image(wf, input_image_comfy_name)
            
            # –ò–Ω–∂–µ–∫—Ç –ø—Ä–æ–º–ø—Ç–æ–≤ (–æ–¥–∏–Ω —Ä–∞–∑, –¥–æ –ø–æ–ø—ã—Ç–æ–∫)
            _inject_hunyuan_i2v_prompts(wf, prompt)
            
            # –ü–æ–ø—ã—Ç–∫–∏ –æ—Ç "—Å–∞–º–æ–≥–æ –∂–∏—Ä–Ω–æ–≥–æ" –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –∫ –±–æ–ª–µ–µ –ª—ë–≥–∫–∏–º
            attempt_indices = list(range(start_idx, -1, -1))
            
            last_err = None
            result = None
            prompt_id = None
            
            for i, pi in enumerate(attempt_indices, start=1):
                preset = HUNYUAN_PRESETS[pi]
                log.info(f"Hunyuan preset attempt {i}/{len(attempt_indices)}: {preset['name']}")
                
                # –ò–Ω–∂–µ–∫—Ç–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–µ—Å–µ—Ç–∞
                _inject_hunyuan_i2v_settings(
                    wf,
                    width=preset["width"],
                    height=preset["height"],
                    num_frames=preset["num_frames"],
                    fps=preset["fps"],
                    steps=preset["steps"],
                    cfg=preset["cfg"],
                    batch_size=preset["batch_size"],
                    weight_dtype=preset["weight_dtype"],
                )
                _inject_hunyuan_noise_seed(wf)
                
                log.info("HunyuanVideo API: skipping checkpoint/UNET auto-select (using workflow defaults)")
                
                # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ ComfyUI
                try:
                    prompt_id = await client.queue_prompt(wf)
                    if not prompt_id:
                        err = (client.last_error or "ComfyUI –æ—Ç–∫–ª–æ–Ω–∏–ª workflow").strip()[:800]
                        log.error(f"ComfyUI rejected workflow: {err}")
                        raise RuntimeError(err)
                    
                    log.info(f"Prompt queued: {prompt_id}")
                    
                    # –ñ–¥—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º timeout
                    timeout_s = min(1800, max(900, 300 + int(preset["num_frames"] * preset["steps"])) )
                    result = await client.wait_for_result(prompt_id, timeout=timeout_s)
                    if result is not None:
                        log.info(f"‚úì HunyuanVideo —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª —Å –ø—Ä–µ—Å–µ—Ç–æ–º {preset['name']}")
                        break
                    
                    # –ï—Å–ª–∏ result None - –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏—á–∏–Ω—É
                    last_err = client.last_error or "unknown error"
                    log.warning(f"Hunyuan attempt failed ({preset['name']}): {last_err}")
                    
                    # –ï—Å–ª–∏ OOM –∏–ª–∏ early fail - –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–µ—Å–µ—Ç
                    if _is_oom_error(last_err) or "not in queue" in last_err.lower() or "without outputs" in last_err.lower():
                        if i < len(attempt_indices):
                            log.info(f"Will retry with lighter preset...")
                            continue
                        else:
                            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å
                            raise RuntimeError(last_err)
                    else:
                        # –î—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ - –Ω–µ –ø—Ä–æ–±—É–µ–º fallback
                        raise RuntimeError(last_err)
                
                except RuntimeError:
                    raise
                except Exception as e:
                    log.exception(f"Unexpected error during Hunyuan generation: {e}")
                    raise RuntimeError(str(e))
            
            if result is None:
                err = last_err or client.last_error or "HunyuanVideo: –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å"
                if _is_oom_error(err):
                    err = (
                        "‚ùå ComfyUI –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (OOM - –Ω–µ—Ö–≤–∞—Ç–∫–∞ VRAM).\n\n"
                        "üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n"
                        "‚Ä¢ –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ ComfyUI —Å --lowvram\n"
                        "‚Ä¢ –ó–∞–∫—Ä–æ–π—Ç–µ –¥—Ä—É–≥–∏–µ GPU-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n"
                        "‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ\n\n"
                        f"–î–µ—Ç–∞–ª–∏: {err}"
                    )
                raise RuntimeError(err)
        
        else:
            # –î–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö workflow ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∏–Ω–∂–µ–∫—Ç –ø—Ä–æ–º–ø—Ç–∞
            _inject_prompt(wf, prompt)
            
            if workflow_name == "flux_dev_fp8":
                _inject_seed_steps_cfg(wf, steps=28, cfg=1.0)
                _inject_resolution(wf, width=1024, height=1024)
            elif workflow_name == "flux_schnell_fp8":
                _inject_seed_steps_cfg(wf, steps=4, cfg=1.0)
                _inject_resolution(wf, width=1024, height=1024)
            elif workflow_name == "sdxl_base_refiner":
                _inject_seed_steps_cfg(wf, steps=20, cfg=7.5)
                _inject_resolution(wf, width=1024, height=1024)
            elif workflow_name == "video_default" or workflow_name == "video_sd15":
                _inject_seed_steps_cfg(wf, steps=20, cfg=7.0)
                _inject_resolution(wf, width=512, height=512)

            if client is None:
                client = ComfyUIClient(settings.comfy_url, settings.comfy_timeout)

            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ–æ—Ç–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –¥—Ä—É–≥–∏—Ö workflow
            input_image_comfy_name = st.get("input_image_comfy_name")
            if input_image_comfy_name:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏–Ω–∂–µ–∫—Ç –¥–ª—è —Å—Ç–∞—Ä—ã—Ö workflow (sdxl, image_edit)
                if validate_input_image(input_image_comfy_name, settings.comfy_input_dir):
                    ok = _inject_image_filename(wf, input_image_comfy_name)
                    if ok:
                        log.info(f"Input image injected for {workflow_name}: {input_image_comfy_name}")
                    else:
                        log.warning(f"Workflow {workflow_name} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")

            # Auto-select: checkpoint –∏ UNET
            ckpt_inputs = _find_inputs(wf, "ckpt_name")
            if ckpt_inputs:
                available = await client.get_checkpoint_names()
                if not available:
                    raise RuntimeError("ComfyUI: –Ω–µ—Ç checkpoints –≤ models/checkpoints")
                current = _get_current_value(wf, "ckpt_name")
                chosen = _choose_checkpoint(available, workflow_name, current)
                if chosen:
                    for inp in ckpt_inputs:
                        inp["ckpt_name"] = chosen
                    log.info(f"Workflow={workflow_name} Checkpoint chosen: {chosen}")

            unet_inputs = _find_inputs(wf, "unet_name")
            if unet_inputs:
                available_u = await client.get_unet_names()
                current_u = _get_current_value(wf, "unet_name")
                chosen_u = _choose_unet(available_u, workflow_name, current_u)
                for inp in unet_inputs:
                    inp["unet_name"] = chosen_u
                log.info(f"Workflow={workflow_name} UNET chosen: {chosen_u}")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ ComfyUI
            pid = await client.queue_prompt(wf)
            if not pid:
                err = (client.last_error or "ComfyUI –æ—Ç–∫–ª–æ–Ω–∏–ª workflow").strip()[:800]
                log.error(f"ComfyUI rejected workflow: {err}")
                raise RuntimeError(err)

            log.info(f"Prompt queued: {pid}")

            # –ñ–¥—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = await client.wait_for_result(pid, timeout=settings.comfy_timeout)
            if not result:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º last_error –¥–ª—è –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                error_msg = client.last_error or "Timeout: ComfyUI –Ω–µ –≤–µ—Ä–Ω—É–ª output"
                error_msg = f"‚ùå {error_msg}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ ComfyUI –∏–ª–∏ –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á."
                log.error(f"Generation failed: {error_msg}")
                raise RuntimeError(error_msg)
        
        # –û–±—â–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–¥–ª—è –≤—Å–µ—Ö workflow)
        if not result:
            raise RuntimeError("ComfyUI –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç.")

        result_bytes = bytes(result["bytes"])
        result_filename = str(result.get("filename") or "output.bin")
        result_mime = str(result.get("mime") or "application/octet-stream")
        output_node = result.get("node_id") or "unknown"
        output_type = result.get("output_type") or "unknown"

        log.info(
            "Result ready: node=%s type=%s filename=%s size=%s bytes mime=%s",
            output_node,
            output_type,
            result_filename,
            len(result_bytes),
            result_mime,
        )

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ç—É—Å-—Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –º–æ–∂–µ–º
        try:
            await status_msg.delete()
        except Exception:
            pass

        max_send_retries = 2
        send_success = False

        for attempt in range(max_send_retries):
            try:
                is_video = result_mime.startswith("video/") or result_filename.lower().endswith(
                    (".mp4", ".webm", ".mov", ".avi")
                )
                input_file = BufferedInputFile(result_bytes, filename=result_filename)

                if is_video:
                    try:
                        await message.answer_video(
                            input_file,
                            caption="‚úÖ –ì–æ—Ç–æ–≤–æ!",
                            supports_streaming=True,
                            reply_markup=get_main_menu_keyboard(lang),
                        )
                        send_success = True
                        log.info("Telegram send: video (%s)", result_filename)
                        break
                    except TelegramBadRequest:
                        await message.answer_document(
                            input_file,
                            caption="‚úÖ –ì–æ—Ç–æ–≤–æ!",
                            reply_markup=get_main_menu_keyboard(lang),
                        )
                        send_success = True
                        log.info("Telegram send: document (%s)", result_filename)
                        break
                else:
                    await message.answer_photo(
                        input_file,
                        caption="‚úÖ –ì–æ—Ç–æ–≤–æ!",
                        reply_markup=get_main_menu_keyboard(lang),
                    )
                    send_success = True
                    log.info("Telegram send: photo (%s)", result_filename)
                    break
            except Exception as send_err:
                log.warning("Send attempt %s failed: %s", attempt + 1, send_err)
                if attempt < max_send_retries - 1:
                    await asyncio.sleep(2)

        if not send_success:
            fallback_path = Path(settings.tmp_dir) / result_filename
            try:
                fallback_path.write_bytes(result_bytes)
            except Exception:
                fallback_path = Path(result_filename)
            await message.answer(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ Telegram.\n"
                f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {fallback_path}",
                reply_markup=get_main_menu_keyboard(lang),
            )

    finally:
        if client is not None:
            await client.close()
        try:
            # –û—á–∏—â–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
            await state.update_data(
                input_image_local_path=None,
                input_image_comfy_name=None,
                generation_mode=None,
                force_video=None,
                video_quality=None
            )
        except Exception:
            pass
        await state.clear()


@router.callback_query(F.data.in_({PHOTO_ACTION_ENHANCE, PHOTO_ACTION_EDIT_PROMPT, PHOTO_ACTION_EDIT_MASK}))
async def cb_photo_actions(callback: CallbackQuery, state: FSMContext, settings) -> None:
    from bot.keyboards.main_menu import get_main_menu_keyboard
    from utils.helpers import get_lang
    
    lang = get_lang(callback.message)
    data = await state.get_data()
    last_photo = data.get("last_photo_comfy")
    if not last_photo:
        await callback.answer("–ù–µ—Ç —Ñ–æ—Ç–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ.")
        return

    action = callback.data
    await callback.answer()

    loader = callback.bot.get("workflow_loader")
    if loader is None:
        loader = WorkflowLoader(settings.workflows_dir)

    wf_name = WORKFLOW_IMAGE_DEFAULT
    if _workflow_exists(loader, WORKFLOW_FLUX_DEV_IMG2IMG):
        wf_name = WORKFLOW_FLUX_DEV_IMG2IMG
    elif _workflow_exists(loader, WORKFLOW_FLUX_SCHNELL_IMG2IMG):
        wf_name = WORKFLOW_FLUX_SCHNELL_IMG2IMG

    if action == PHOTO_ACTION_ENHANCE:
        client = ComfyUIClient(settings.comfy_url, settings.comfy_timeout)
        prompt = "enhance photo, keep subject and composition, more details, sharp focus, realistic, high quality"
        negative = "blurry, lowres, deformed, artifacts, bad anatomy, cartoon, anime, oversaturated"
        await callback.message.answer("‚ú® –£–ª—É—á—à–∞—é —Ñ–æ—Ç–æ‚Ä¶")
        try:
            await _run_image_job(
                message=callback.message,
                client=client,
                loader=loader,
                workflow_name=wf_name,
                input_image_name=last_photo,
                prompt=prompt,
                negative=negative,
                denoise=0.25,
                settings=settings,
            )
        except Exception as e:
            log.exception(f"Enhance failed: {e}")
            await callback.message.answer(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        finally:
            await client.close()
        return

    if action == PHOTO_ACTION_EDIT_PROMPT:
        await state.update_data(
            pending_photo_action="edit_prompt",
            mask_photo_comfy=None,
            pending_photo_workflow=wf_name,
            pending_photo_denoise=0.55,
        )
        await callback.message.answer("‚úèÔ∏è –ü—Ä–∏—à–ª–∏ –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (—á—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å/–¥–æ–±–∞–≤–∏—Ç—å).")
        return

    if action == PHOTO_ACTION_EDIT_MASK:
        await state.update_data(
            pending_photo_action="edit_mask_wait_mask",
            mask_photo_comfy=None,
            pending_photo_workflow=WORKFLOW_IMAGE_DEFAULT,
            pending_photo_denoise=0.65,
        )
        await callback.message.answer("üé≠ –ü—Ä–∏—à–ª–∏ –º–∞—Å–∫—É (—á/–±: –±–µ–ª—ã–º ‚Äî –º–µ–Ω—è—Ç—å, —á—ë—Ä–Ω—ã–º ‚Äî –æ—Å—Ç–∞–≤–∏—Ç—å).")
        return


@router.message(F.photo)
async def msg_photo_mask_router(message: Message, state: FSMContext, settings) -> None:
    """
    –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ —Ä–µ–∂–∏–º–µ mask-edit –∏ –ø—Ä–∏—Å–ª–∞–ª —Ñ–æ—Ç–æ ‚Äî —ç—Ç–æ –º–∞—Å–∫–∞.
    """
    st = await state.get_data()
    if st.get("pending_photo_action") != "edit_mask_wait_mask":
        return

    from utils.helpers import get_lang
    
    lang = get_lang(message)
    mask_name = await save_telegram_photo(message, settings.tmp_dir, prefix="mask")
    
    # –ö–æ–ø–∏—Ä—É–µ–º –º–∞—Å–∫—É –≤ ComfyUI input
    mask_comfy = ensure_comfy_input_image(mask_name, settings.comfy_input_dir)
    
    await state.update_data(mask_photo_comfy=mask_comfy, pending_photo_action="edit_mask_prompt")
    await message.answer("‚úÖ –ú–∞—Å–∫–∞ –ø–æ–ª—É—á–µ–Ω–∞. –¢–µ–ø–µ—Ä—å –ø—Ä–∏—à–ª–∏ –ø—Ä–æ–º–ø—Ç (—á—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å –≤ –±–µ–ª—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö).")



